{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cao/projects/HumanTOMATO/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "torch.Size([1, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cao/projects/HumanTOMATO/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# Load text and motion data\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tma.models.architectures.temos.textencoder.distillbert_actor import DistilbertActorAgnosticEncoder\n",
    "from tma.models.architectures.temos.motionencoder.actor import ActorAgnosticEncoder\n",
    "from collections import OrderedDict\n",
    "\n",
    "modelpath = 'distilbert-base-uncased'\n",
    "\n",
    "textencoder = DistilbertActorAgnosticEncoder(modelpath, num_layers=4)\n",
    "motionencoder = ActorAgnosticEncoder(nfeats=126, vae = True, num_layers=4)\n",
    "\n",
    "\"\"\"\n",
    "load model here\n",
    "You need to normalize the motion data with mean and std.\n",
    "For motionx, they are stored in './deps/t2m/motionx/vector_623/Comp_v6_KLD01/meta/*.npy'\n",
    "\"\"\"\n",
    "\n",
    "motion = torch.randn(1, 64, 126)    # B = 1, T = , D = , need normalization\n",
    "lengths = [64]\n",
    "text_loc = textencoder([\"a man is running\"]).loc\n",
    "motion_loc = motionencoder(motion, lengths).loc\n",
    "\n",
    "print(text_loc.shape)\n",
    "print(motion_loc.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separate text encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch.nn.functional as f\n",
    "\n",
    "\n",
    "# t2m_textencoder = SentenceTransformer(\n",
    "#                     \"sentence-transformers/sentence-t5-xl\"\n",
    "#                 ).to(\"cuda\")\n",
    "\n",
    "text_encoder = SentenceTransformer(\n",
    "                \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "            )\n",
    "\n",
    "sbert_embedding = torch.tensor(text_encoder.encode([\"a man is running\"]))\n",
    "sbert_embedding = f.normalize(sbert_embedding, dim=1)\n",
    "# append to retrieval_sbert_embedding then save\n",
    "print(sbert_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sbert_embedding = torch.tensor(text_encoder.encode([\"a man is running\"]))\n",
    "sbert_embedding = f.normalize(sbert_embedding, dim=1)\n",
    "# append to retrieval_sbert_embedding then save\n",
    "print(sbert_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded_inputs is:  {'input_ids': tensor([[ 101, 1037, 2158, 2003, 2770,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
      "Shape of the output is:  torch.Size([1, 256])\n",
      "tensor([[-7.8206e-01,  1.0115e-01, -1.2464e+00, -1.4071e+00, -1.2713e+00,\n",
      "          7.0725e-01, -1.4456e+00,  7.0572e-01,  1.7185e-01, -1.3222e+00,\n",
      "          3.8473e-01, -2.8311e-01, -7.1576e-01,  1.8202e+00, -3.2605e-02,\n",
      "         -6.4899e-01,  2.4506e-01,  3.7061e-02, -8.5351e-03, -9.4823e-01,\n",
      "          7.0347e-01,  1.9185e+00,  2.8431e-01, -6.2639e-01,  2.2022e+00,\n",
      "          1.2188e+00, -7.7114e-01, -1.8912e+00, -1.3866e+00, -5.3211e-03,\n",
      "          5.3484e-01,  1.2507e+00, -1.1876e+00, -8.2671e-01,  2.7289e-01,\n",
      "         -1.2918e+00,  9.5213e-01,  9.0805e-01, -2.2187e-02,  1.7782e+00,\n",
      "          6.6882e-01,  1.7420e+00, -3.0283e-01, -1.5952e-01, -1.6173e+00,\n",
      "          1.0506e+00,  5.8134e-01,  1.5830e+00,  2.0144e+00, -1.0662e-01,\n",
      "          5.9543e-01,  1.7398e-01, -1.5931e+00,  6.7786e-01, -3.4605e-01,\n",
      "          6.6201e-01,  6.2224e-01,  4.4048e-02, -4.6046e-01,  1.0569e+00,\n",
      "         -6.5772e-01,  7.6254e-01, -4.6270e-01,  2.3636e-01,  6.3249e-01,\n",
      "         -1.0575e+00, -1.4661e+00, -2.4489e-02, -1.5280e+00, -6.8239e-01,\n",
      "          1.5441e+00,  1.1820e+00, -9.5040e-01,  1.9081e+00, -2.4870e-01,\n",
      "          2.1876e-01,  1.0282e+00,  2.9857e+00,  1.0316e+00, -3.2842e-02,\n",
      "         -9.7141e-01,  1.5754e+00, -4.7524e-01, -1.0333e+00, -3.0980e-01,\n",
      "         -3.2534e-01,  1.1374e+00,  2.7741e-01, -1.2424e+00, -1.1223e-03,\n",
      "          6.7158e-01,  1.2719e+00, -8.9300e-01, -3.4728e-01, -8.0588e-01,\n",
      "          3.5749e-01, -1.2841e-01,  2.0731e+00, -1.3193e-01,  9.8468e-01,\n",
      "          6.1995e-01,  2.5199e-01,  1.1475e+00, -1.0596e+00, -8.8574e-01,\n",
      "          2.5784e+00, -8.9105e-01, -1.6096e-01, -5.6317e-01, -6.2677e-01,\n",
      "         -1.5126e-01,  8.7117e-01,  1.5428e-01, -4.2179e-01, -3.8537e-01,\n",
      "         -1.1541e+00,  6.9587e-01,  5.5421e-01, -1.8144e+00, -5.2921e-01,\n",
      "         -9.3882e-01, -4.6506e-01, -1.5341e+00, -4.8732e-01,  3.9427e-01,\n",
      "          2.4717e-02, -5.7073e-01,  9.1148e-01, -9.6103e-01,  1.1841e+00,\n",
      "         -3.2789e-01,  7.7381e-01,  3.2092e-01,  8.7921e-01, -2.9512e-01,\n",
      "         -3.4605e-01, -1.0150e+00,  1.0103e+00,  2.1309e-01,  1.6148e-01,\n",
      "          3.3728e-01, -2.1813e-01, -2.1573e+00,  1.4992e-01, -1.5761e+00,\n",
      "         -3.4213e-01, -1.1045e+00, -5.2509e-01, -1.9763e-01,  1.6426e+00,\n",
      "          7.9353e-01,  3.0827e-01,  1.4091e+00, -5.1568e-01, -6.4450e-01,\n",
      "         -1.3305e+00, -3.0842e-02,  5.5818e-01,  2.0747e+00, -2.8187e-01,\n",
      "          1.1303e-01,  1.1175e+00, -8.6692e-01,  6.5421e-01,  9.2882e-01,\n",
      "          1.2212e+00,  8.8528e-01,  1.5137e+00, -1.9534e+00,  1.2288e+00,\n",
      "         -1.7368e+00, -4.8426e-01, -1.0407e+00,  4.8148e-01, -2.1696e+00,\n",
      "          1.3520e+00,  5.9491e-01, -7.5720e-03, -8.3182e-01, -1.4785e+00,\n",
      "         -1.2478e-01, -1.6019e+00, -1.0616e+00, -1.3343e+00, -1.0599e+00,\n",
      "          2.1877e-02,  1.6955e+00,  6.3025e-01, -5.3897e-01,  4.5436e-01,\n",
      "          9.8892e-01, -1.3557e-01,  1.2656e+00,  3.5509e-01, -7.9683e-01,\n",
      "         -1.9462e+00,  8.1149e-01, -1.2149e-01, -1.8247e+00,  9.4892e-01,\n",
      "         -1.6469e-01, -5.8819e-02,  8.9942e-01,  1.3538e+00, -1.3801e+00,\n",
      "          8.4623e-01, -4.9257e-01,  8.0774e-01, -2.1577e-01, -3.9397e-01,\n",
      "         -7.3160e-01, -4.0371e-01,  1.5796e+00,  1.0516e+00,  4.4124e-01,\n",
      "         -4.9004e-02,  2.6614e-01, -1.9962e+00, -4.0365e-01,  2.2615e+00,\n",
      "         -1.1035e+00, -1.8302e-02, -2.2886e-01,  2.9775e-01,  9.8407e-01,\n",
      "         -2.5964e-02,  2.4548e-01, -4.3986e-01, -1.0356e+00, -1.3480e+00,\n",
      "         -6.3224e-01,  8.1776e-01, -1.2266e+00,  1.5431e-01,  5.2745e-01,\n",
      "          2.6939e-01,  6.4762e-01, -1.4375e+00, -3.4249e-01,  1.0458e+00,\n",
      "         -1.0797e+00,  5.6442e-01, -8.1825e-01, -8.4809e-01, -9.9658e-02,\n",
      "          1.7443e+00, -1.0502e+00, -8.0775e-01,  9.6709e-01,  7.5350e-01,\n",
      "         -9.0667e-01, -5.2466e-01, -1.7221e+00,  1.0927e+00, -2.1442e-01,\n",
      "         -1.4280e-01]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tma.models.operator import PositionalEncoding\n",
    "import torch.nn as nn\n",
    "\n",
    "latent_dim = 256\n",
    "num_layers = 4\n",
    "dropout = 0.1\n",
    "ff_size = 1024\n",
    "num_heads = 4\n",
    "activation = \"gelu\"\n",
    "texts = [\"a man is running\"]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath)\n",
    "text_model = AutoModel.from_pretrained(modelpath)\n",
    "text_encoded_dim = text_model.config.hidden_size\n",
    "encoded_dim = text_encoded_dim\n",
    "# Define a projection layer\n",
    "projection = nn.Sequential(nn.ReLU(), nn.Linear(encoded_dim, latent_dim))\n",
    "sequence_pos_encoding = PositionalEncoding(latent_dim, dropout)\n",
    "seq_trans_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=latent_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ff_size,\n",
    "            dropout=dropout,\n",
    "            activation=activation,\n",
    "        )\n",
    "seqTransEncoder = nn.TransformerEncoder(\n",
    "            seq_trans_encoder_layer, num_layers=num_layers\n",
    "        )\n",
    "emb_token = nn.Parameter(torch.randn(latent_dim))\n",
    "\n",
    "encoded_inputs = tokenizer(texts, return_tensors=\"pt\", padding=True)\n",
    "print(\"encoded_inputs is: \" , encoded_inputs)\n",
    "# Pass the encoded inputs to the DistilBERT model\n",
    "output = text_model(**encoded_inputs.to(text_model.device))\n",
    "\n",
    "text_encoded = output.last_hidden_state\n",
    "mask = encoded_inputs.attention_mask.to(dtype=bool)\n",
    "\n",
    "x = projection(text_encoded)\n",
    "bs, nframes, _ = x.shape\n",
    "x = x.permute(1, 0, 2)\n",
    "\n",
    "emb_token = torch.tile(emb_token, (bs,)).reshape(bs, -1)\n",
    "# adding the embedding token for all sequences\n",
    "xseq = torch.cat((emb_token[None], x), 0)\n",
    "\n",
    "# create a bigger mask, to allow attend to emb\n",
    "token_mask = torch.ones((bs, 1), dtype=bool, device=x.device)\n",
    "aug_mask = torch.cat((token_mask, mask), 1)\n",
    "\n",
    "# add positional encoding\n",
    "xseq = sequence_pos_encoding(xseq)\n",
    "final = seqTransEncoder(xseq, src_key_padding_mask=~aug_mask)\n",
    "\n",
    "print(\"Shape of the output is: \", final[0].shape)\n",
    "print(final[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3256,  0.8143, -1.5370,  0.8725, -0.1511, -0.4471,  0.9860,  0.0897,\n",
      "         -0.6547,  1.1179,  0.2964, -0.0765,  1.6888,  1.7420, -0.1253, -0.4458,\n",
      "         -0.0558,  2.7246,  0.1661,  0.7913, -1.0926, -0.0479, -0.1698,  0.8765,\n",
      "         -0.6255,  0.9815, -1.4775, -0.2375, -1.4362,  0.2580,  1.1114, -0.2313,\n",
      "         -0.2006, -0.6877,  1.0223, -1.2454,  1.1648,  1.2484, -0.9671, -0.5842,\n",
      "          1.0904,  0.6741, -0.8994, -1.5404, -0.0630,  1.6932, -0.1999,  0.3714,\n",
      "          0.9772,  0.9038,  0.7037, -0.6228, -1.2222,  1.1707, -1.7129, -0.8946,\n",
      "         -2.7043,  0.9849,  0.1471,  0.2925,  0.0120, -0.4709,  0.3676, -1.1064,\n",
      "         -0.5375,  0.0693,  0.3215, -0.2041,  0.4732, -0.3161,  2.2470,  0.8540,\n",
      "          0.1883,  1.2110, -0.3793,  0.2704,  0.1963,  1.2377,  1.1619, -0.6099,\n",
      "          0.8589,  0.8103,  1.3656,  0.1401,  1.0720,  0.0448, -1.6851,  0.9291,\n",
      "         -1.2997,  0.0653, -1.3914,  0.8716, -1.6376, -0.3468, -1.4277,  0.3694,\n",
      "         -0.9638,  1.2117, -0.7278,  0.3929,  0.0688, -0.4693,  0.3650, -1.3762,\n",
      "          0.3194, -1.8904, -1.1854,  1.6363, -0.4646,  0.4805,  0.6179, -0.2254,\n",
      "         -1.4048,  0.2362, -1.0124,  0.2461,  0.7666, -0.0593,  1.6104,  0.1743,\n",
      "         -1.1328,  1.1002, -1.5123,  1.4509, -0.5902,  0.5632,  0.3994, -0.0560,\n",
      "          0.3822, -0.5855,  0.5467, -1.8595, -0.2814,  0.9101,  0.1563,  1.4359,\n",
      "         -0.6561,  0.3870,  0.8466, -0.6012, -0.5703, -0.2273,  0.1205, -0.6930,\n",
      "         -1.6144,  0.2388, -1.8741,  2.7241, -2.2265, -1.1894,  0.2760, -1.3379,\n",
      "          0.9778,  0.5604, -0.1198, -0.5990, -1.5185, -0.9421, -0.4647,  0.4170,\n",
      "         -1.7174,  1.7466,  1.2754, -0.1664, -1.5296, -0.2109,  0.2433, -2.2422,\n",
      "         -1.8636,  0.7227, -0.3315,  0.9723, -0.6474, -0.0663,  0.3532,  1.3903,\n",
      "         -0.9306,  0.3200, -0.9106,  1.6616, -0.4175,  2.1855, -0.6127,  0.8242,\n",
      "          0.7088,  0.8656,  1.2788, -0.4835, -0.5410,  1.4431, -1.7509,  0.3401,\n",
      "          1.0870, -0.1338, -0.0410, -0.6093, -1.4427,  0.1178, -0.3566,  0.8324,\n",
      "          0.1943, -0.1109, -1.2242,  0.8053, -0.6372,  0.4093,  0.4022,  0.1666,\n",
      "          0.6429, -0.1007, -0.0220,  0.7195, -1.1731,  0.4199, -0.2000,  1.3175,\n",
      "         -1.8738, -0.4411, -0.8473,  0.0986,  0.6847, -0.3203,  1.5906,  0.4193,\n",
      "          0.3106,  0.3015,  1.2263,  1.3391, -1.0471, -0.3046, -1.5808, -0.0726,\n",
      "         -1.4760,  1.4885, -0.2846,  0.4017,  0.3722,  0.4175,  0.7516, -0.1648,\n",
      "         -0.6626, -0.8474,  0.2165, -1.6488, -0.3650, -0.5413,  0.5973,  1.1689,\n",
      "         -2.9302, -0.1551, -0.4625, -1.3796,  0.3878,  0.7021,  0.3016,  2.4632]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from tma.models.architectures.temos.textencoder.distillbert_actor import DistilbertActorAgnosticEncoder\n",
    "\n",
    "textencoder = DistilbertActorAgnosticEncoder(modelpath, num_layers=4)\n",
    "\n",
    "text_loc = textencoder(texts).loc\n",
    "\n",
    "print(text_loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
